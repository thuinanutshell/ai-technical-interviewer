# Ava â€“ AI Technical Interviewer

Ava is an AI-powered mock technical interviewer that helps job seekers practice coding and behavioral interviews by simulating real-world interview conditions and offering real-time feedback.

## âš™ï¸ Tech Stack

![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi&logoColor=white)
![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=next.js&logoColor=white)
![Supabase](https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&logo=supabase&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)

![OpenAI Whisper](https://img.shields.io/badge/OpenAI%20Whisper-412991?style=for-the-badge&logo=openai&logoColor=white)
![Gemini API](https://img.shields.io/badge/Gemini%20API-4285F4?style=for-the-badge&logo=google&logoColor=white)
![Railway](https://img.shields.io/badge/Railway-0B0D0E?style=for-the-badge&logo=railway&logoColor=white)
![Vercel](https://img.shields.io/badge/Vercel-000000?style=for-the-badge&logo=vercel&logoColor=white)
---

## Table of Contents

1. [Day 1: User Flow & Research](#day-1-user-flow--research)
2. [Day 2: Database Design & Pseudocode](#day-2-database-design--pseudocode)
3. [Day 3: Feature: Audio Transcription & PDF Parsing](#day-3-feature-audio-transcription--pdf-parsing)
4. [Day 4: Feature: AI Conversation & Follow-up Questions](#day-4-feature-ai-conversation--follow-up-questions)
5. [Day 5: Feature: Analytics (If Time Permits)](#day-5-feature-analytics-if-time-permits)
6. [Day 6: CI/CD & Deployment](#day-6-cicd--deployment)
7. [Day 7: Documentation](#day-7-documentation)

---

# Day 1: User Flow & Research

## Problem Statement

Interview prep is one of the most important parts of the job application process. Preparing alone can feel isolating, and finding the right accountability partner is often challenging. **Ava** is a mock AI interviewer designed to simulate real interviews and provide users with a structured environment to think out loud and receive instant feedback.

### Coding Mode

In Coding Mode, users follow the [UMPIRE framework](https://guides.codepath.com/compsci/UMPIRE-Interview-Strategy):

1. **Understand** â€“ Clarify the problem using examples and questions.
2. **Match** â€“ Identify the problem category and known strategies.
3. **Plan** â€“ Use visualizations and write pseudocode.
4. **Implement** â€“ Write the code in the sandbox.
5. **Review** â€“ Walk through the code with test cases.
6. **Evaluate** â€“ Analyze time/space complexity and tradeoffs.

![image](https://github.com/user-attachments/assets/b63e255a-46ea-4c14-b5dd-b00d105e6f9f)

#### Coding Mode Flow

1. User selects a topic (e.g., Trees, DP)
2. A random question is displayed
3. The user starts the timer
4. User records answer for each UMPIRE step
5. The system transcribes the answer and gives AI feedback
6. Final feedback is provided based on performance

---

### Behavioral Mode

![image](https://github.com/user-attachments/assets/3f835add-60a9-4a2f-af4e-4356b2fb1dda)

#### Behavioral Mode Flow

1. User uploads resume (PDF)
2. The system parses it to create context
3. AI generates personalized questions
4. User records responses
5. AI transcribes and asks up to 2 follow-up questions
6. Final AI feedback is provided

---

## Feature Prioritization

| Feature                     | Priority | Reason |
|----------------------------|-------------|--------|
| Audio Recording & Transcription | ğŸ”¥ğŸ”¥ğŸ”¥ | Core to simulating interviews because the key focus here is to let the users **practice thinking out loud in a structured way** |
| PDF Parsing                | ğŸ”¥ğŸ”¥ğŸ”¥ | Enables resume-based behavioral questions because the system needs a **context** to generate a list of appropriate questions |
| AI Conversation            | ğŸ”¥ğŸ”¥ğŸ”¥ | Enables dynamic mock interview with a **two-way** interaction |
| Code Editor           | ğŸ”¥ğŸ”¥ğŸ”¥ | Enables **code editor-like** to type out the implementation |
| Follow-up Questions        | ğŸ”¥ğŸ”¥   | Adds realism and depth |
| Analytics                  | ğŸ”¥ğŸ”¥   | Tracks user progress |
| Text-to-Speech             | ğŸ”¥     | AI Interviewer speaks like humans instead of just returning text|
| Timer                      | ğŸ”¥     | Simulates real interview pressure |
| Authentication             | ğŸ”¥     | Required for account setup |

## Technical Research
| Feature                     | Technology | Notes |
|----------------------------|-------------|--------|
| STT - Audio Recording & Transcription | MediaStream Recording API, OpenAI Whisper API | The first API can be used to record audio in the browser, and the second API is used to transcribe the audio into text.|
| PDF Parsing                | PDF.js, Gemini API (with built-in feature for PDF parsing), PyMuPDF| Both can read and parse PDF into text ready to be used in the AI's context, but if I use Gemini API, it will cost towards the number of tokens used |
| AI Conversation            | Gemini API, Claude API | Enables dynamic mock interview |
| Code Editor           | CodeMirror | Enables **code editor-like** to type out the implementation |
| Follow-up Questions        | Gemini API, Claude API   | Adds realism and depth |
| Analytics                  | Rechart.js   | Tracks user progress by providing some data visualizations |
| TTS - Text-to-Speech       | ElevenLabs API   | AI Interviewer speaks like humans instead of just returning text only |
| Authentication             | Supabase     | Required for account setup |

---

# Day 2: Database Design & Pseudocode

### Database Design
For the first version of this app, I had to make a decision between complexity and storage. The part that got me thinking is that: *Do I really need to store the audio files from the users?* My reasoning is that 

1. Saved audio files are not of significant importance because what matters is that the user can receive the assessment of their performance after a mock interview session and suggestions on how to improve the next time. One might argue that if the user needs to review the audio of themselves later, or re-run the analysis. But as someone whose main focus is to practice **thinking out loud in a structured** way, reviewing audio is way less important than having a functional space to do as much practice as possible.
2. Saved audio files cost more storage, while the value per storage is not high, unless the key feedback is to use the data to train some models, which is not the case here.

As a result, my final database schema design is shown below, which I believe strikes a balance between simplicity and functionality with the following tables:
| Table     | Description                                                                                         |
|-----------|-----------------------------------------------------------------------------------------------------|
| **User**  | Stores basic user personal information                                                              |
| **Question** | A question bank that stores all questions (both coding and behavioral). The `type` field indicates whether the question is behavioral, tree, dynamic programming, etc. |
| **Resume** | A simple table to store a user's resume data                                                       |
| **Session** | Stores a complete mock interview session for a user that includes the initial context (coding question description or parsed resume data) |
| **Message** | Stores the conversation between the user and the AI system                                        |
| **Feedback** | Stores the feedback for the session as a whole                                                   |


<img width="1115" alt="Screenshot 2025-07-08 at 9 54 49â€¯AM" src="https://github.com/user-attachments/assets/1b3e83bf-b643-4d4c-8ed3-702d774423f6" />


## Structure & Pseudocode for Backend & Frontend
### Tech Stack
| Layer          | Tech                                 | Reason                                                                                                 |
| -------------- | ------------------------------------ | ---------------------------------------------------------------------------------------------------------- |
| **Backend**    | FastAPI                              | Lightweight, async-friendly, production-ready. I had extensive experience with Flask before, so I want to try something similar.|
| **Frontend**   | Next.js                              | Hybrid SSR/SPA; pairs well with Vercel and Supabase Auth out of the box.|
| **Auth**       | Supabase Auth                        | Simple to set up, good support for email/password and OAuth; tightly integrates with Next.js.|
| **Database**   | Supabase DB (PostgreSQL)             | Simplify the process of setting up the database|
| **Deployment** | Railway (backend), Vercel (frontend) | Simple, scalable, CI/CD-friendly.|

![image](https://github.com/user-attachments/assets/04229f23-8891-4632-ab48-dc6a676f8cc2)

### Backend
| **Action**                           | **Method**             | **Route**                         | **Description**                                                              |
| ------------------------------------ | ---------------------- | --------------------------------- | ---------------------------------------------------------------------------- |
| Create a new interview session       | `POST`                 | `/sessions`                       | Starts a new session (e.g. after selecting a question or uploading a resume) |
| Get session details                  | `GET`                  | `/sessions/{session_id}`          | Fetch a specific sessionâ€™s metadata, messages, etc.                          |
| Submit a user answer (audio)         | `POST`                 | `/sessions/{session_id}/messages` | Adds a new message from the user (with audio blob) to the session            |
| Respond with system feedback         | `POST`                 | `/sessions/{session_id}/messages` | Same route: system's follow-up is added as another message                   |
| Get full conversation history        | `GET`                  | `/sessions/{session_id}/messages` | Returns the list of user + system messages                                   |
| Generate final feedback for session  | `POST`                 | `/sessions/{session_id}/feedback` | Generates and stores tone summary, speech rate, overall evaluation           |
| Get feedback for session             | `GET`                  | `/sessions/{session_id}/feedback` | Retrieve saved feedback (for review or display)                              |
| Upload & parse resume                | `POST`                 | `/resumes`                        | Upload resume (PDF), parse it on server, store parsed data                   |
| Get parsed resume for user           | `GET`                  | `/resumes/user/{user_id}`         | Retrieve a userâ€™s uploaded resumes                                           |
| Generate questions based on resume   | `POST`                 | `/questions/generated`            | Dynamically generate questions from a parsed resume                          |
| Create a new custom question         | `POST`                 | `/questions`                      | Add a manual question (coding or behavioral) to the question bank            |
| Get all questions                    | `GET`                  | `/questions`                      | Retrieve question bank (optionally filtered by type or user)                 |
| Get a specific question              | `GET`                  | `/questions/{question_id}`        | Fetch one question by ID                                                     |
| Delete a question                    | `DELETE`               | `/questions/{question_id}`        | Remove a question (admin or owner only)                                      |

### Frontend 
#### Lofi Mockup

The app has two primary interview modes: **Coding** and **Behavioral**.

![image](https://github.com/user-attachments/assets/b7436152-97bc-4bc6-9460-e48b75eb2cd6)

#### Next.js App Structure
```
/frontend
â”‚
â”œâ”€â”€ app/                      # App router structure (Next.js 13+)
â”‚   â”œâ”€â”€ page.jsx              # Landing or redirect to dashboard
â”‚   â”‚
â”‚   â”œâ”€â”€ auth/                 # Supabase auth pages
â”‚   â”‚   â”œâ”€â”€ login/page.jsx
â”‚   â”‚   â””â”€â”€ register/page.jsx
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboard/            # Entry point after login (choose mode)
â”‚   â”‚   â”œâ”€â”€ layout.jsx
â”‚   â”‚   â””â”€â”€ page.jsx
â”‚   â”‚
â”‚   â”œâ”€â”€ session/              # Dynamic session pages
â”‚   â”‚   â””â”€â”€ [id]/page.jsx     # Live session: chat, code, question flow, feedback
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                  # Optional: Next.js local route handlers (if needed)
â”‚
â”œâ”€â”€ components/               # Reusable UI and logic components
â”‚   â”œâ”€â”€ session/              # Interview-specific components
â”‚   â”‚   â”œâ”€â”€ ChatBox.jsx
â”‚   â”‚   â”œâ”€â”€ CodeEditor.jsx
â”‚   â”‚   â”œâ”€â”€ QuestionDisplay.jsx
â”‚   â”‚   â”œâ”€â”€ Feedback.jsx
â”‚   â”‚   â””â”€â”€ CreateQuestionModal.jsx
â”‚   â”‚
â”‚   â”œâ”€â”€ shared/               # Generic UI components
â”‚   â”‚   â”œâ”€â”€ AudioRecorder.jsx
â”‚   â”‚   â”œâ”€â”€ LoadingSpinner.jsx
â”‚   â”‚   â””â”€â”€ ErrorMessage.jsx
â”‚
â”œâ”€â”€ hooks/                    # Custom React hooks
â”‚   â”œâ”€â”€ useSession.js         # Handle session ID, mode, etc.
â”‚   â”œâ”€â”€ useChat.js            # Multi-turn conversation logic
â”‚   â””â”€â”€ useAudioRecorder.js   # Audio recording logic
â”‚
â”œâ”€â”€ lib/                      # Utility and service functions
â”‚   â”œâ”€â”€ api.js                # Calls FastAPI backend
â”‚   â””â”€â”€ supabaseClient.js     # Supabase instance config
â”‚
â”œâ”€â”€ constants/                # Static data (question types, enums)
â”‚   â””â”€â”€ questionTypes.js
â”‚
â”œâ”€â”€ public/                   # Static assets (logo, icons)
â”œâ”€â”€ styles/                   # Global CSS & Tailwind config
â”‚   â””â”€â”€ globals.css
â”‚
â”œâ”€â”€ .env.local                # Supabase, backend URLs
â”œâ”€â”€ tailwind.config.js
â”œâ”€â”€ postcss.config.js
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---
## Day 3: Feature: Audio Transcription & PDF Parsing

- Integrate Whisper (or another model) for transcription
- Use `pdfplumber`, `PyMuPDF`, or third-party API for resume parsing
- Normalize parsed content for embedding/context

### Demo
### Tests

---

## Day 4: Feature: AI Conversation & Follow-up Questions

- Use OpenAI/Gemma with structured prompts
- Memory chain to store context (e.g., LangChain)
- Rule-based or confidence-threshold triggers for follow-up

### Demo
### Tests

---

## Day 5: Feature: Analytics (If Time Permits)

- Track completion, AI ratings, time per question, weak areas
- Visualize via simple dashboard (e.g., Recharts or Chart.js)

### Demo
### Tests

---

## Day 6: CI/CD & Deployment

- GitHub Actions for test + lint checks
- Deploy backend (Railway)
- Deploy frontend (Vercel)
- Use `.env` for secrets + environment configs

---

## Day 7: Documentation

- README with:
  - Overview
  - Feature List
  - Installation & Setup
  - API Reference
- Record a Loom demo
